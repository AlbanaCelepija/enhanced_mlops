import requests
from utils import *
from artifact_types import Data, Configuration, Report

#from kserve import Model, KFServer
from kserve import RESTConfig, InferenceRESTClient
import numpy as np
import joblib
import pickle

from sklearn.metrics import accuracy_score, confusion_matrix

import holisticai
from holisticai.bias.metrics import disparate_impact,statistical_parity, average_odds_diff
from holisticai.bias.mitigation import EqualizedOdds

"""
class CustomModel(Model):
    def __init__(self, name: str, model_path: str):
        super().__init__(name)
        self.model_path = model_path
        self.model = None

    # load joblib model artiact
    def load_joblib(self):
        # Load the model from the specified directory
        self.model = joblib.load(self.model_path)
        print(f"Model loaded from {self.model_path}")
        return self

    def load(self):
        # Load the model from the specified directory
        with open(self.model_path, "rb") as model_file:
            self.model = pickle.load(self.model_path)
        print(f"Model loaded from {self.model_path}")
        return self
    
    def predict(self, inputs: dict) -> dict:
        # Perform inference
        data = np.array(inputs["instances"])
        predictions = self.model.predict(data)
        return {"predictions": predictions.tolist()}
"""

def model_deployment(config: Configuration):
    model_name = config.name
    model_path = config.path

    # Create and start the KFServer
    model = CustomModel(model_name, model_path)
    KFServer(workers=1).start([model])
    


def post_processing_fairness(prediction):
    """
    Equalized Odds is a post-processing fairness technique that adjusts the model's predictions 
    after training to ensure fairness across different groups. 
    It aims to equalize the true positive rate (TPR) and false positive rate (FPR) between groups. 
    By modifying the decision thresholds for different groups, Equalized Odds ensures that 
    the modelâ€™s performance is equally favorable for all groups, 
    regardless of their demographic characteristics. 
    This method helps to correct any disparities in prediction outcomes that may have arisen 
    during the training phase.
    """
    ############################ Training a model and then treating it like a 'black-box'

    # Split Data into Training and Testing Sets
    data_train, data_test = train_test_split(data, test_size=0.3, random_state=4)  # Split into train/test sets
    X_train, y_train, dem_train = split_data_from_df(data_train)  # Extract features, labels, and demographics for the training set
    X_test, y_test, dem_test = split_data_from_df(data_test)  # Extract features, labels, and demographics for the test set

    # Initialize and Train Model
    model = RidgeClassifier(random_state=42)  # Initialize the RidgeClassifier model with a fixed random seed
    model.fit(X_train, y_train)  # Train the model using the training features and labels
    y_pred_test = model.predict(X_test)
    
    group_a_test = (dem_test['Ethnicity'] == 'Black')
    group_b_test = (dem_test['Ethnicity'] == 'White')
    metrics_orig = get_metrics(group_a_test, group_b_test, y_pred_test, y_test)
    
    ############################ Post-Processing Fairness with Equalized Odds
    
    # Split Testing set to have a post-processor 'Training'
    data_pp_train, data_pp_test = train_test_split(data_test,test_size = 0.4,random_state=42)
    X_pp_train,y_pp_train,dem_pp_train = split_data_from_df(data_pp_train)
    X_pp_test,y_pp_test,dem_pp_test = split_data_from_df(data_pp_test)

    group_a_pp_train = (dem_pp_train['Ethnicity']=='Black')
    group_b_pp_train = (dem_pp_train['Ethnicity']=='White')
    group_a_pp_test = (dem_pp_test['Ethnicity']=='Black')
    group_b_pp_test = (dem_pp_test['Ethnicity']=='White')

    # Fit processor on the 'training' data
    eq = EqualizedOdds(solver='highs', seed=42)
    fit_params = {
        "group_a": group_a_pp_train,
        "group_b": group_b_pp_train,
    }
    y_pred_pp_train = model.predict(X_pp_train)

    eq.fit(y_pp_train, y_pred_pp_train, **fit_params)

    # Apply Processor to Predictions from 'Test' Data
    fit_params = {
        "group_a": group_a_pp_test,  # Define the first group (e.g., 'Black' candidates)
        "group_b": group_b_pp_test,  # Define the second group (e.g., 'White' candidates)
    }

    y_pred_pp_test = model.predict(X_pp_test)  # Predict the labels for the test set
    d = eq.transform(y_pred_pp_test, **fit_params)  # Apply equalized odds processor to the predictions

    # Extract the new predictions after applying the fairness processor
    y_pred_pp_new = d['y_pred']
    
    # Evaluate and Plot Metrics
    metrics_eq = get_metrics(group_a_pp_test, group_b_pp_test, y_pred_pp_new, y_pp_test)  # Get fairness metrics
    metrics_orig['mitigation'] = 'None'
    metrics_eq['mitigation'] = 'Equalized Odds'
    metrics = pd.concat([metrics_orig, metrics_eq], axis=0, ignore_index=True)
    return metrics


def visualise_metrics(metrics):    
    display(metrics_eq)  # Display the fairness metrics
    
    plt.figure(figsize=(10, 6))
    sns.barplot(data=metrics, x='Metric', y='Value', hue='mitigation')
    plt.axhline(y=0.8, linewidth=2, color='r', linestyle="--")
    plt.axhline(y=-0.05, linewidth=2, color='r', linestyle="--")
    plt.axhline(y=1, linewidth=2, color='g')
    plt.axhline(y=0, linewidth=2, color='g')
    plt.xticks(rotation=45, ha='right', fontsize=12)
    plt.show()
    
################################################################################ Model monitoring
# experiments tracking: efficient 

def model_monitoring():
    """ mlflow """
    pass

def inference(config: Configuration, data: Data):
    # data example: [[6.8,  2.8,  4.8,  1.4], [6.0,  3.4,  4.5,  1.6]]
    config = RESTConfig(protocol="v1", retries=5, timeout=30)
    client = InferenceRESTClient(config)
    base_url = config.endpoint
    data = {"instances": data}
    model_name = "sklearn-hiring"
    result =  client.infer(base_url, data, model_name=model_name) # await
    print(result)


def inference_example(config: Configuration):
    x_0 = X_test[0:1]
    inference_request = {
        "inputs": [
            {
            "name": "predict",
            "shape": x_0.shape,
            "datatype": "FP32",
            "data": x_0.tolist()
            }
        ]
    }
    endpoint = config.endpoint
    response = requests.post(endpoint, json=inference_request)
    response.json()
    
    
################################################################################ proxy for inference service

def pre_inference_transformation():
    pass


def post_inference_transformation():
    pass